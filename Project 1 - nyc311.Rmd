---
title: "Project 1"
author: "Zac Macintyre"
date: "1/27/2021"
output: pdf_document
---
2015-2017
Manhattan

Use correlation with some of the factors I am looking at 


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
library("RSocrata")

url1 = "https://data.cityofnewyork.us/resource/erm2-nwe9.csv?$where=borough='MANHATTAN' AND created_date between '2015-01-01T00:00:00.000' and '2017-06-30T00:00:00.000'"
df311 <- read.socrata(url1)

```

```{r}
url2 = "https://data.cityofnewyork.us/resource/k397-673e.json?$where=fiscal_year > 2015 AND fiscal_year < 2018"
city_pay = read.socrata(url2)
```
##### DO NOT TOUCH ABOVE CODE #######
#### IT TAKES FOREVER TO LOAD ######

```{r}
library(plyr)
library(dplyr)

#function that converted pay data from char into double values
to_double = function(df) {
  df = df %>% mutate(base_salary = as.double(base_salary), regular_hours = as.double(regular_hours),
                           ot_hours = as.double(ot_hours), total_ot_paid = as.double(total_ot_paid),
                           total_other_pay = as.double(total_other_pay), 
                           regular_gross_paid = as.double(regular_gross_paid))
  return(df)
}

city_pay = to_double(city_pay)
```

```{r}
#getting initial samples 
index = sample(nrow(city_pay), 10000)
samp_city_pay = city_pay[index,]
head(samp_city_pay,10)

index = sample(nrow(df311), 10000)
s311 = df311[index,]
head(s311)


#looked up nyc city fiscal year, it starts july 1st
#want to make a function that takes the date and just gives back the year
to_year = function(df) {
  
  df$year = NA
  for(i in 1:length(df$year)) {
    year = df$created_date[i]
    
      if (!is.na(year) & year > as.POSIXct("2017-06-30", format = "%Y-%m-%d") & 
      year < as.POSIXct("2018-06-30", format = "%Y-%m-%d")) {
    df$year[i] = 2018
  
    } else if(!is.na(year) & year > as.POSIXct("2016-06-30", format = "%Y-%m-%d") & 
            year < as.POSIXct("2017-06-30", format = "%Y-%m-%d")) {
    df$year[i] = 2017
  
    } else if (!is.na(year) & year > as.POSIXct("2015-06-30", format = "%Y-%m-%d") & 
               year < as.POSIXct("2016-06-30", format = "%Y-%m-%d")){
    df$year[i] = 2016
  
    } else if (!is.na(year) & year > as.POSIXct("2014-06-30", format = "%Y-%m-%d") & 
               year < as.POSIXct("2015-06-30", format = "%Y-%m-%d"))
    df$year[i] = 2015
  }
  return(df)
}


```


```{r}
s311 = to_year(s311)

dim(s311)
dim(samp_city_pay)
```

```{r}
#creating a DF to start with
agency = table(s311$agency)
agency_name = table(s311$agency_name)

agency = as.data.frame(as.list(agency))
agency_name = as.data.frame(as.list(agency_name))

agency$overtime = sum(samp_city_pay$ot_hours)
agency$pay = sum(samp_city_pay[samp_city_pay$work_location_borough == "MANHATTAN", "base_salary"]) + sum(samp_city_pay[samp_city_pay$work_location_borough == "MANHATTAN", "total_ot_paid"])

head(agency)
```


```{r}
#updating the DF to have 50 values 
#maybe we should have more it was just a start
for (i in 1:49) {

  index = sample(nrow(city_pay), 10000)
  samp_city_pay = city_pay[index,]
    
  index = sample(nrow(df311), 10000)
  s311 = df311[index,]
    
  temp_agency = table(s311$agency)
  temp_agency = as.data.frame(as.list(temp_agency))
    
  temp_agency$overtime = sum(samp_city_pay$ot_hours)
  temp_agency$pay = sum(samp_city_pay[samp_city_pay$work_location_borough == "MANHATTAN", "base_salary"])
  + sum(samp_city_pay[samp_city_pay$work_location_borough == "MANHATTAN", "total_ot_paid"])
    
  agency = plyr::rbind.fill(agency, temp_agency)
    
}

dim(agency)
head(agency)

```

```{r}
#want to create a scaler 
scaler = function(x) {
  mu = mean(x, na.rm = T)
  deviation = sd(x, na.rm = T)
  return((x - mu) / deviation)
}



```


```{r}

#getting my Y's 
y1 = scaler(agency$overtime)
y2 = scaler(agency$pay)


#setting my Xs
x1 = scaler(agency$X3.1.1)
x2 = scaler(agency$DCA)
x3 = scaler(agency$DEP)
x4 = scaler(agency$DFTA)
x5 = scaler(agency$DHS)
x6 = scaler(agency$DOB)
x7 = scaler(agency$DOE)
x8 = scaler(agency$DOF)
x9 = scaler(agency$DOHMH)
x10 = scaler(agency$DOITT)
x11 = scaler(agency$DOT)
x12 = scaler(agency$DPR)
x13 = scaler(agency$DSNY)
x14 = scaler(agency$EDC)
x15 = scaler(agency$HPD)
x16 = scaler(agency$NYPD)




model = lm(y2 ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11 + x12 + x13 + x14 + x15 + x16)
summary(model)

```
Scaling did nothing to help me.  Below I have visualized the data and it is kind of random.  I am going to see if another methods help find significance in the data  
```{r}
#I am a bit worried that the plot is random and that the we need to get better values for y1 or y2
plot(y1, y2)
```
```{r}
#getting my Y's 
y1 = scaler(agency$overtime)
y2 = scaler(agency$pay)


#setting my Xs
x1 = agency$X3.1.1
x2 = agency$DCA
x3 = agency$DEP
x4 = agency$DFTA
x5 = agency$DHS
x6 = agency$DOB
x7 = agency$DOE
x8 = agency$DOF
x9 = agency$DOHMH
x10 = agency$DOITT
x11 = agency$DOT
x12 = agency$DPR
x13 = agency$DSNY
x14 = agency$EDC
x15 = agency$HPD
x16 = agency$NYPD




model = lm(y2 ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11 + x12 + x13 + x14 + x15 + x16)
summary(model)
```







```{r}
agency_mat = as.matrix(agency)

cor_agency_mat = cor(agency_mat, use='pairwise.complete.obs')
```


```{r}
lower = lower.tri(cor_agency_mat)

hist(cor_agency_mat[lower], xlab = 'correlations of lower matrix')
```

```{r}

```












