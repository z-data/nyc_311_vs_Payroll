---
title: "Project 1"
author: "Zac Macintyre"
date: "1/27/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
library("RSocrata")

url1 = "https://data.cityofnewyork.us/resource/erm2-nwe9.csv?$where=borough='MANHATTAN' AND created_date between '2014-07-01T00:00:00.000' and '2017-06-30T00:00:00.000'"
df311 <- read.socrata(url1)

```

```{r}
url2 = "https://data.cityofnewyork.us/resource/k397-673e.json?$where=fiscal_year > 2014 AND fiscal_year < 2018"
city_pay = read.socrata(url2)
```
##### DO NOT TOUCH ABOVE CODE #######
#### IT TAKES FOREVER TO LOAD ######


So, all the code below did not really lead to any insights.  I am not sure when you are going to look at it, but this is all I will get done tonight.  I need to think about how else to analyze this to get something actionable.


```{r}
library(plyr)
library(dplyr)

#function that converted pay data from char into double values
to_double = function(df) {
  df = df %>% mutate(base_salary = as.double(base_salary), regular_hours = as.double(regular_hours),
                           ot_hours = as.double(ot_hours), total_ot_paid = as.double(total_ot_paid),
                           total_other_pay = as.double(total_other_pay), 
                           regular_gross_paid = as.double(regular_gross_paid))
  return(df)
}

city_pay = to_double(city_pay)
```

```{r}
#looked up nyc city fiscal year, it starts july 1st
#want to make a function that takes the date and just gives back the year
to_year = function(df) {
  
  df$year = NA
  for(i in 1:length(df$year)) {
    year = df$created_date[i]
    
      if (!is.na(year) & year > as.POSIXct("2017-06-30", format = "%Y-%m-%d") & 
      year < as.POSIXct("2018-06-30", format = "%Y-%m-%d")) {
    df$year[i] = 2018
  
    } else if(!is.na(year) & year > as.POSIXct("2016-06-30", format = "%Y-%m-%d") & 
            year < as.POSIXct("2017-06-30", format = "%Y-%m-%d")) {
    df$year[i] = 2017
  
    } else if (!is.na(year) & year > as.POSIXct("2015-06-30", format = "%Y-%m-%d") & 
               year < as.POSIXct("2016-06-30", format = "%Y-%m-%d")){
    df$year[i] = 2016
  
    } else if (!is.na(year) & year > as.POSIXct("2014-06-30", format = "%Y-%m-%d") & 
               year < as.POSIXct("2015-06-30", format = "%Y-%m-%d"))
    df$year[i] = 2015
  }
  return(df)
}



```
```{r}
#getting initial samples 
index = sample(nrow(city_pay), 10000)
samp_city_pay = city_pay[index,]
head(samp_city_pay,10)

index = sample(nrow(df311), 10000)
s311 = df311[index,]
head(s311)

```

Creating a new city pay DF with only the relevant departments
```{r}
# getting complaint types where on average there is at least 1 complaint every other day
complaints = table(s311$complaint_type) > 183
complaints = names(complaints)[complaints == T]


#getting depts that have high complaint rates 
new = s311[s311$complaint_type %in% complaints, ]
dept = toupper(unique(new$agency_name))
sort(unique(city_pay$agency_name))
dept

dept1 = c("DEPARTMENT OF TRANSPORTATION", "POLICE DEPARTMENT", "DEPARTMENT OF BUILDINGS", "DEPT. OF HOMELESS SERVICES", 
          "TAXI & LIMOUSINE COMMISSION", "DEPT OF ENVIRONMENT PROTECTION", "HOUSING PRESERVATION & DVLPMNT")

#called it new city 
new_city = city_pay[city_pay$agency_name %in% dept1, ]
new_city$total_pay = new_city$base_salary + new_city$total_ot_paid

```

This code seems like we are getting somewhere.  There are a little over 1000 complaints a day on average in Manhattan.  At 10,000 samples that is close to 10 days of random samples.  There we have complaints that come in at over 15 times a day in those samples with the complaints being above 150.  We repeat this 10 times to get 100 random days throughout the year.  This out put will give us dept names and the frequency with which they happened in each of the 10 times the for loop ran
```{R}
N = 10
dept_comp = c()
comps = c()
for (i in 1:N) {
  
  index = sample(nrow(df311), 10000)
  s311 = df311[index,]
  
  complaints = table(s311$complaint_type) > 150
  complaints = names(complaints)[complaints == T]
  complant_det = unique(s311[s311$complaint_type %in% complaints, "agency_name"])
  
  comps = append(comps, complaints)
  dept_comp = append(dept_comp, complant_det)
  
}

table(dept_comp)
dept_names = unique(dept_comp)

table(comps)
comp_names = unique(comps)

```

Trying to engineer the new feature 
```{r}
#getting names for all the deptartments, had to do by hand because they do not match in each DF
dept1 = c("DEPARTMENT OF BUILDINGS", "DEPT OF ENVIRONMENT PROTECTION", "DEPT OF HEALTH/MENTAL HYGIENE", "HOUSING PRESERVATION & DVLPMNT",
          "DEPARTMENT OF TRANSPORTATION", "POLICE DEPARTMENT", "DEPT. OF HOMELESS SERVICES", "TAXI & LIMOUSINE COMMISSION")

#function for calculating the mean of total pay
new_mean = function(df) {
  return( mean(df$total_pay, na.rm = T))
}
#function for calculating the total complaints per dept 
new_sum = function(df) {
  return(length(df$complaint_type))
}

#splitting the City Pay data by dept and getting the mean pay
new_city.split = split(new_city, new_city$agency_name)
mu = sapply(new_city.split, new_mean)

#splitting the 311 by dept and getting the total complaints
new311 = df311[df311$agency_name %in% dept_names, ]
new311.split = split(new311, new311$agency_name)
total = sapply(new311.split, new_sum)

#removing the depts that fall under larger depts 
total["New York City Police Department"] = total["New York City Police Department"] + total["Traffic Management Center"]
total["Department of Housing Preservation and Development"] = total["Department of Housing Preservation and Development"] + total["Division of Alternative Management"]


total = total[1:9]
total = total[-6]

#initializing the pay per complaint and changing the names in the total to be the same as mu
names(total) = dept1
per_comp = total

#for loop to get the ratio
for (i in dept1) {
  per_comp[i] = mu[i]/total[i]
}

#making it a DF so it easy to manage
per_comp = as.data.frame(t(per_comp))
per_comp
```





```{r}
#making year DFs just to see some data year by year easily 
year_2015 = city_pay[city_pay$fiscal_year == 2015,]
year_2016 = city_pay[city_pay$fiscal_year == 2016,]
year_2017 = city_pay[city_pay$fiscal_year == 2017,]

```

I had an idea to look at the pay data by year and maybe learn something.  I havent deleted any code, that I think might still somehow be useful
```{r}
#section to compare some features of these years 

#667,305,085 Million dollar difference between 2017-1016 
sum(year_2017$base_salary + year_2017$total_ot_paid) - sum(year_2016$base_salary + year_2016$total_ot_paid) 

#1,061,901,727 Billion dollar difference between 2016-2015
sum(year_2016$base_salary + year_2016$total_ot_paid) - sum(year_2015$base_salary + year_2015$total_ot_paid)

#562266
length(year_2017$agency_name)

#544817
length(year_2016$agency_name)

#577880
length(year_2015$agency_name)

year_2015$total_pay = year_2015$base_salary + year_2015$total_ot_paid
year_2016$total_pay = year_2016$base_salary + year_2016$total_ot_paid
year_2017$total_pay = year_2017$base_salary + year_2017$total_ot_paid

```

Trying to explore the data differently.  I am going top down, seeing who the upper 16th qu is and seeing what those places do
```{r}
#3rd Qu = 76706,  max = 300,000,   upper 16th = 106537
summary(year_2015[year_2015$total_pay > 76706, "total_pay"])

#3rd Qu = 81254,  max = 350,000,   upper 16th = 112926
summary(year_2016[year_2016$total_pay > 81254, "total_pay"])

#3rd Qu = 82805,  max = 350,000,  upper 16th = 115605
summary(year_2017[year_2017$total_pay > 82805, "total_pay"])

```

The original DF was very long tried to make it much smaller 
```{r}
rich_2015 = year_2015[year_2015$total_pay > 76706, ]

rich_2016 = year_2016[year_2016$total_pay > 81254, ]

rich_2017 = year_2017[year_2017$total_pay > 82805, ]


rich = plyr::rbind.fill(rich_2015, rich_2016, rich_2017)

rich$full_name = paste(rich$first_name, rich$last_name)


rich[rich$total_pay > 250000 & rich$work_location_borough == "MANHATTAN",]
```
Above didnt do much for me.  Now on too looking at those most complaint types throughout the years 


```{r}
#end of the night thoughts to maybe do something with 2moro
hist(samp_city_pay$ot_hours)
overtime = samp_city_pay[samp_city_pay$ot_hours > 100,]
table(overtime$agency_name)

#converting the years
s311 = to_year(s311)

#getting dimensions of my samples
dim(s311)
dim(samp_city_pay)




mean(new_city[new_city$agency_name == "POLICE DEPARTMENT", "base_salary"])

mean(new_city[new_city$agency_name == "POLICE DEPARTMENT" & new_city$ot_hours > 0, "total_ot_paid"])
```



```{r}






```
new feature = average salary / over complaint  

linear model on new features vs average salary of the depts 


I am getting tired, but these tables and seem to be interesting somehow for evaluating what the city's money goes to
```{r}

```



This code is all about trying to set up a linear regression model with agency being what I want to regress pay against.  It didnt result really anything of significance, but I think this is because they way I got pay isnt right.  i randomly drew 10,000 employees and got their total pay.  I think we need to correlate the pay more to the important departments
```{r}
#creating a DF to start with
agency = table(s311$agency)
agency_name = table(s311$agency_name)

agency = as.data.frame(as.list(agency))
agency_name = as.data.frame(as.list(agency_name))

agency$overtime = sum(samp_city_pay$ot_hours)
agency$pay = sum(samp_city_pay[samp_city_pay$work_location_borough == "MANHATTAN", "base_salary"]) + sum(samp_city_pay[samp_city_pay$work_location_borough == "MANHATTAN", "total_ot_paid"])

head(agency)
```


```{r}
#updating the DF to have N values 
N = 250
for (i in 1:N) {

  index = sample(nrow(city_pay), 10000)
  samp_city_pay = city_pay[index,]
    
  index = sample(nrow(df311), 10000)
  s311 = df311[index,]
    
  temp_agency = table(s311$agency)
  temp_agency = as.data.frame(as.list(temp_agency))
    
  temp_agency$overtime = sum(samp_city_pay$ot_hours)
  temp_agency$pay = sum(samp_city_pay[samp_city_pay$work_location_borough == "MANHATTAN", "base_salary"])
  + sum(samp_city_pay[samp_city_pay$work_location_borough == "MANHATTAN", "total_ot_paid"])
    
  agency = plyr::rbind.fill(agency, temp_agency)
    
}

dim(agency)
head(agency)

```

```{r}
#want to create a scaler, this just normalizes the data to ~N(0,1) 
scaler = function(x) {
  mu = mean(x, na.rm = T)
  deviation = sd(x, na.rm = T)
  return((x - mu) / deviation)
}

```


```{r}
#getting my Y's 
y1 = scaler(agency$overtime)
y2 = scaler(agency$pay)


#setting my Xs
x1 = scaler(agency$X3.1.1)
x2 = scaler(agency$DCA)
x3 = scaler(agency$DEP)
x4 = scaler(agency$DFTA)
x5 = scaler(agency$DHS)
x6 = scaler(agency$DOB)
x7 = scaler(agency$DOE)
x8 = scaler(agency$DOF)
x9 = scaler(agency$DOHMH)
x10 = scaler(agency$DOITT)
x11 = scaler(agency$DOT)
x12 = scaler(agency$DPR)
x13 = scaler(agency$DSNY)
x14 = scaler(agency$EDC)
x15 = scaler(agency$HPD)
x16 = scaler(agency$NYPD)



#nothing really happened here I got x2 was significant at .05
model = lm(y2 ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11 + x12 + x13 + x14 + x15 + x16)
summary(model)

```

Scaling did nothing to help me.  Below I have visualized the data and it is random, a residual plot should look like this.  I am going to see if another methods help find significance in the data  

```{r}
#I am a bit worried that the plot is random and that the we need to get differnt values for y1 or y2
plot(y2)
```
```{r}
#getting my Y's 
y1 = agency$overtime
y2 = agency$pay


#setting my Xs
x1 = agency$X3.1.1
x2 = agency$DCA
x3 = agency$DEP
x4 = agency$DFTA
x5 = agency$DHS
x6 = agency$DOB
x7 = agency$DOE
x8 = agency$DOF
x9 = agency$DOHMH
x10 = agency$DOITT
x11 = agency$DOT
x12 = agency$DPR
x13 = agency$DSNY
x14 = agency$EDC
x15 = agency$HPD
x16 = agency$NYPD

#just normal lm()
#x2 was significant again at .05
model = lm(y2 ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11 + x12 + x13 + x14 + x15 + x16)
summary(model)
```



I m trying to see what a correlation matrix tells me about the data

```{r}
#getting a correlation matrix
agency_mat = as.matrix(agency)

cor_agency_mat = cor(agency_mat, use='pairwise.complete.obs')
```


```{r}
#plotting correlations
lower = lower.tri(cor_agency_mat)

hist(cor_agency_mat[lower], xlab = 'correlations of lower matrix')
```
The data is pretty non-correlated.  My guess is we have to add different criteria to this data to help get anything.  Just using Dept names for who responded to 311 calls did not really help anything.  Maybe there is something there that pretty much none of them have anything to do with total pay.  My guess is that the way I sampled total pay randomized it too much.  In other words, if we try to use this we need t ocontrol for year or something.













